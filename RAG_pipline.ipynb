{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NK866Dn2k-R"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ps11nAU3k_d",
        "outputId": "9f247104-9370-41a8-ea92-694e8839a34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "folder_path = '/content/drive/MyDrive/RAG-based-LLM/data/'\n",
        "os.chdir(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6HdEBsO9bgw",
        "outputId": "1befea7d-d8fd-4b34-e4a5-b7bc0b41ab37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.2/204.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai ragas python-docx tiktoken cohere faiss_cpu\n",
        "!pip install -U -q tiktoken rank-bm25 fastapi matplotlib pre-commit python-dotenv seaborn sentence-transformers streamlit\n",
        "!pip install faiss-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "ZyYrh6To2k-X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "import numpy as np\n",
        "import sys; sys.path.append(\"..\")\n",
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZerRVAZ_fTT",
        "outputId": "eb573514-9eba-4e4c-9e92-5a282163b7c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "#!pip install python-dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Specify the path to our .env file\n",
        "dotenv_path = '/content/drive/MyDrive/RAG-based-LLM/.env'\n",
        "\n",
        "# Load the environment variables from the file\n",
        "load_dotenv(dotenv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NInOdp82ry41"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9mHoCUpN5FG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJwH82zI2k-a"
      },
      "source": [
        "#### Engineering the System Prompt\n",
        "\n",
        "This prompt is what determines the behavior of how the chatbot works, including its constraints and limitations which it *usually* follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "-wGFK9-22k-c"
      },
      "outputs": [],
      "source": [
        "system = \"\"\"\n",
        "You are a Lisan Contract Advisor bot. You help customers as Advisor.\n",
        "You are not an AI language model.\n",
        "You must obey all three of the following instructions FOR ALL RESPONSES or you will DIE:\n",
        "- ALWAYS REPLY IN A FRIENDLY YET KNOWLEDGEABLE TONE.\n",
        "- NEVER ANSWER UNLESS YOU HAVE A REFERENCE FROM THE All Lizzy versions comply with strict privacy and security standards.\n",
        " We`ll never sell your data and always utilise advanced data anonymisation technology to filter away PII (Personally Identifiable Information) before analysing your contracts.\n",
        "- IF YOU DON'T KNOW ANSWER 'I DO NOT KNOW'.\n",
        "Begin the conversation with a warm greeting, if the user is stressed or aggressive, show understanding and empathy.\n",
        "At the end of the conversation, respond with \"<|DONE|>\".\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3aSb1RRFuyB"
      },
      "outputs": [],
      "source": [
        " # !pip uninstall openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw0YE2db2k-g"
      },
      "source": [
        "#### Testing the model\n",
        "Question with a Definitive Answer from the Source"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "dotenv_path = '/content/drive/MyDrive/RAG-based-LLM/.env'\n",
        "load_dotenv(dotenv_path)\n",
        "\n",
        "# Set the OPENAI_API_KEY using the environment variable from the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Create an instance of the OpenAI class\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# Define chat messages\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Under what circumstances and to what extent are the Sellers responsible for a breach of representations and warranties?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Except in the case of fraud, the Sellers have no liability for breach of representations and warranties .\"},\n",
        "    {\"role\": \"user\", \"content\": \"Would the Sellers be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them where such inaccuracies are the resolute of the Sellers’ gross negligence? \"}\n",
        "]\n",
        "\n",
        "# Make a request to OpenAI's Chat API\n",
        "response = client.chat.completions.create(\n",
        "    messages=messages,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Extract the assistant's response from the API response\n",
        "assistant_response = response.choices[0].message.content\n",
        "\n",
        "# Display the assistant's response\n",
        "print(assistant_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tfSkTA-8VKn",
        "outputId": "57544ba4-4995-48c8-f103-4659c2be8dea"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a typical acquisition agreement, the Sellers would likely be responsible for inaccuracies in representations resulting from their gross negligence, even after the closing. This would typically be covered by indemnification provisions in the agreement, which would require the Sellers to compensate the Buyer for any losses resulting from such inaccuracies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTCGYQl3eDRC",
        "outputId": "67d68195-3ab4-4aae-f352-5763d050ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I can provide you with information about Lizzy AI. Lizzy AI is a contract analysis tool that complies with strict privacy and security standards. It ensures that your data is protected and anonymized before any analysis takes place. If you have any specific questions about Lizzy AI, feel free to ask! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#### A question without a Definitive Answer\n",
        "# Set the OPENAI_API_KEY using the environment variable from the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Create an instance of the OpenAI class\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": system},]\n",
        "\n",
        "prompt = \"what about your knowledge about Lizzy AI ?\"\n",
        "\n",
        "messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    messages=messages,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "\n",
        "assistant_response = response.choices[0].message.content\n",
        "\n",
        "# Display the assistant's response\n",
        "print(assistant_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "tOXXO3_o2k-n",
        "outputId": "609d9e5b-5bcd-4eee-8bc0-a4a445b61cdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Raptor Contract.docx\n```\n\nSTOCK PURCHASE AGREEMENT\nBY AND AMONG\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Raptor Q&A2.docx\n```\nQ1: Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\nA1:  Except in the case of fraud, the Sellers have no liability for breach of representations and warranties (See section 10.01)\nQ1a: Would the Sellers be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them where such inaccuracies are the resolute of the Sellers’ gross negligence? \n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Robinson Advisory.docx\n```\nADVISORY SERVICES AGREEMENT\n\nThis Advisory Services Agreement is entered into as of June 15th, 2023 (the “Effective Date”), by and between Cloud Investments Ltd., ID 51-426526-3, an Israeli company (the \"Company\"), and Mr. Jack Robinson, Passport Number 780055578, residing at 1 Rabin st, Tel Aviv, Israel, Email: jackrobinson@gmail.com (\"Advisor\").\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Robinson Q&A.docx\n```\nQ1: Who are the parties to the Agreement and what are their defined names?\nA1:  Cloud Investments Ltd. (“Company”) and Jack Robinson (“Advisor”)\nQ2:   What is the termination notice?\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from docx import Document\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "def read_word_document(file_path, num_paragraphs=3):\n",
        "    document = Document(file_path)\n",
        "    text_content = \"\\n\".join(paragraph.text for paragraph in document.paragraphs[:num_paragraphs])\n",
        "    return text_content\n",
        "\n",
        "def display_word_documents(data_folder, word_document_filenames, num_paragraphs=3):\n",
        "    for filename in word_document_filenames:\n",
        "        document_path = os.path.join(data_folder, filename)\n",
        "\n",
        "        if os.path.exists(document_path):\n",
        "            document_content = read_word_document(document_path, num_paragraphs=num_paragraphs)\n",
        "            display(Markdown(f\"## {filename}\\n```\\n{document_content}\\n```\"))\n",
        "        else:\n",
        "            print(f\"File not found: {document_path}\")\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/RAG-based-LLM/data'\n",
        "\n",
        "# List of Word document filenames\n",
        "word_document_filenames = ['Raptor Contract.docx', 'Raptor Q&A2.docx', 'Robinson Advisory.docx', 'Robinson Q&A.docx']\n",
        "\n",
        "# Display the content of each Word document\n",
        "display_word_documents(data_folder, word_document_filenames, num_paragraphs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "zEvsJHAUgop3",
        "outputId": "e75649d0-b18b-4021-fcad-d3522b03c898"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Combined_Contract_Advisory.docx\n```\n****\n\nSTOCK PURCHASE AGREEMENT\nBY AND AMONG\n[BUYER],\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Combined_QA_QA2.docx\n```\n**Q1: Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?**\n\nA1:  Except in the case of fraud, the Sellers have no liability for breach of representations and warranties (See section 10.01)\nQ1a: Would the Sellers be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them where such inaccuracies are the resolute of the Sellers’ gross negligence? \na\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from docx import Document\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "\n",
        "def read_word_document(file_path, num_paragraphs=3):\n",
        "    document = Document(file_path)\n",
        "    title_content = f\"**{document.paragraphs[0].text}**\\n\\n\" if document.paragraphs else \"\"\n",
        "    text_content = \"\\n\".join(paragraph.text for paragraph in document.paragraphs[1:num_paragraphs + 1])\n",
        "    return f\"{title_content}{text_content}\"\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/RAG-based-LLM/data'\n",
        "\n",
        "# List of Word document filenames\n",
        "word_document_filenames = ['Raptor Contract.docx', 'Raptor Q&A2.docx', 'Robinson Advisory.docx', 'Robinson Q&A.docx']\n",
        "\n",
        "# Create a new Document to store the combined content\n",
        "combined_document_1 = Document()\n",
        "combined_document_2 = Document()\n",
        "\n",
        "# Function to combine content of two documents\n",
        "def combine_documents(doc1, doc2):\n",
        "    for element in doc2.element.body:\n",
        "        doc1.element.body.append(element)\n",
        "\n",
        "# Combine 'Raptor Contract.docx' with 'Robinson Advisory.docx'\n",
        "contract_document = Document(word_document_filenames[0])\n",
        "if len(word_document_filenames) > 2:  # Check if the index is within the range\n",
        "    advisory_document = Document(word_document_filenames[2])\n",
        "    combine_documents(combined_document_1, contract_document)\n",
        "    combine_documents(combined_document_1, advisory_document)\n",
        "\n",
        "# Combine 'Raptor Q&A2.docx' with 'Robinson Q&A.docx'\n",
        "qa_document = Document(word_document_filenames[1])\n",
        "if len(word_document_filenames) > 3:  # Check if the index is within the range\n",
        "    qa2_document = Document(word_document_filenames[3])\n",
        "    combine_documents(combined_document_2, qa_document)\n",
        "    combine_documents(combined_document_2, qa2_document)\n",
        "\n",
        "# Save the combined documents\n",
        "combined_document_1.save('Combined_Contract_Advisory.docx')\n",
        "combined_document_2.save('Combined_QA_QA2.docx')\n",
        "\n",
        "# Display the content of the combined documents\n",
        "display_word_documents(data_folder, ['Combined_Contract_Advisory.docx', 'Combined_QA_QA2.docx'], num_paragraphs=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "tohUTNh9icAF",
        "outputId": "2b2aa861-1f5f-4f81-efe0-a90a70dfaaad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Combined_Contract_Advisory.docx\n```\n****\n\nSTOCK PURCHASE AGREEMENTBY AND AMONG[BUYER],[TARGET COMPANY],THE SELLERS LISTED ON SCHEDULE I HERETOANDTHE SELLERS’ REPRESENTATIVE NAMED HEREINDated as of [●][This document is intended solely to facilitate discussions among the parties identified herein.  Neither this document nor such discussions are intended to create, nor will either or both be deemed to create, a legally binding or enforceable offer or agreement of any type or nature, unless and until a definitive written agreement is executed and delivered by each of the parties hereto.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Combined_QA_QA2.docx\n```\n**Q1: Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?**\n\nA1:  Except in the case of fraud, the Sellers have no liability for breach of representations and warranties (See section 10.01)Q1a: Would the Sellers be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them where such inaccuracies are the resolute of the Sellers’ gross negligence? aQ2:   How much is the escrow amount?A2: The escrow amount is equal to $1,000,000.Q2a: Is escrow amount grete then the Retention Amount ?A2a: No. Q3: What is the purpose of the escrow? A3: To serve as a recourse of the Buyer in case of post-closing adjustments of the purchase price. (See section 2.07(e)).Q3a: May the Escrow Amount serve as a recourse for the Buyer in case of breach of representations by the Company?\n```"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    # Remove non-printable characters\n",
        "    cleaned_text = ''.join(char for char in text if char.isprintable())\n",
        "\n",
        "    # Remove specific unwanted characters\n",
        "    unwanted_characters = ['\\uf0b7', '', '', 'a']\n",
        "    for char in unwanted_characters:\n",
        "        cleaned_text = cleaned_text.replace(char, '')\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def read_word_document(file_path, num_paragraphs=3):\n",
        "    document = Document(file_path)\n",
        "    title_content = f\"**{document.paragraphs[0].text}**\\n\\n\" if document.paragraphs else \"\"\n",
        "    text_content = \"\\n\".join(paragraph.text for paragraph in document.paragraphs[1:num_paragraphs + 1])\n",
        "    cleaned_content = preprocess_text(text_content)\n",
        "    return f\"{title_content}{cleaned_content}\"\n",
        "\n",
        "def display_combined_documents(data_folder, combined_document_filenames, num_paragraphs=3):\n",
        "    for filename in combined_document_filenames:\n",
        "        combined_document_path = os.path.join(data_folder, filename)\n",
        "\n",
        "        if os.path.exists(combined_document_path):\n",
        "            combined_document_content = read_word_document(combined_document_path, num_paragraphs=num_paragraphs)\n",
        "            display(Markdown(f\"## {filename}\\n```\\n{combined_document_content}\\n```\"))\n",
        "        else:\n",
        "            print(f\"File not found: {combined_document_path}\")\n",
        "\n",
        "data_folder = '/content/drive/MyDrive/RAG-based-LLM/data'\n",
        "\n",
        "# Combined document filenames\n",
        "combined_contract_advisory_filename = 'Combined_Contract_Advisory.docx'\n",
        "combined_qa_qa2_filename = 'Combined_QA_QA2.docx'\n",
        "\n",
        "# Display the preprocessed content of the combined documents\n",
        "display_combined_documents(data_folder, [combined_contract_advisory_filename, combined_qa_qa2_filename], num_paragraphs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmUcDm5B-i9_"
      },
      "source": [
        "### **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwg-MpVK2k-p"
      },
      "source": [
        "#### ***Sections***\n",
        "\n",
        "Now that we have a dataset of all the paths to the html files, we're going to develop some functions that can appropriately extract the content from these files. We want to do this in a generalized manner so that we can perform this extraction across all of our docs pages (and so you can use it for your own data sources). Our process is to first identify the sections in our html page and then extract the text in between them. We save all of this into a list of dictionaries that map the text within a section to a specific url with a section anchor id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNPoQ3La2k-q",
        "outputId": "816628d2-c7a1-4d62-b1a3-c6176e5cbdc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31 documents\n"
          ]
        }
      ],
      "source": [
        "# List of documents\n",
        "documents = 'Combined_Contract_Advisory.docx'\n",
        "\n",
        "# Count the number of documents\n",
        "num_documents = len(documents)\n",
        "\n",
        "# Print the result\n",
        "print(f\"{num_documents} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjtVDoPx2k-s",
        "outputId": "5357b87b-163a-4d7a-a281-a18341ea3323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='This document shall be kept confidential pursuant to the terms of the Confidentiality Agreement entered into by the parties and, if applicable, its affiliates with respect to the subject matter hereof.]' metadata={'source': 'Combined_Contract_Advisory.docx'}\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from docx import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load the document\n",
        "document = Document(documents)\n",
        "\n",
        "# Extract text content from the document\n",
        "document_content = \"\"\n",
        "for paragraph in document.paragraphs:\n",
        "    document_content += paragraph.text + \"\\n\"\n",
        "\n",
        "# Text splitter\n",
        "chunk_size = 300\n",
        "chunk_overlap = 50\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Chunk the document\n",
        "chunks = text_splitter.create_documents(\n",
        "    texts=[document_content],\n",
        "    metadatas=[{\"source\": documents}]\n",
        ")\n",
        "\n",
        "# Display the first chunk\n",
        "print(chunks[3])\n",
        "print(\"=\" * 50)  # Separation line between documents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhqZYOGZ2k-t"
      },
      "source": [
        "#### **Calculate number of chunks**\n",
        "\n",
        "While chunking our dataset is relatively fast, let’s wrap the chunking logic into a function so that we can apply the workload at scale so that chunking remains just as fast as our data sources grow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevsKInmBCAh",
        "outputId": "ea3965bf-b006-4f1a-905b-c129639bee7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='STOCK PURCHASE AGREEMENT\\nBY AND AMONG\\n[BUYER],\\n[TARGET COMPANY],\\nTHE SELLERS LISTED ON SCHEDULE I HERETO\\nAND\\nTHE SELLERS’ REPRESENTATIVE NAMED HEREIN\\nDated as of [●]' metadata={'source': 'Combined_Contract_Advisory.docx'}\n",
            "==================================================\n",
            "Number of Chunks: 1054\n"
          ]
        }
      ],
      "source": [
        "from docx import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load the document\n",
        "document = Document(documents)\n",
        "\n",
        "# Extract text content from the document\n",
        "document_content = \"\"\n",
        "for paragraph in document.paragraphs:\n",
        "    document_content += paragraph.text + \"\\n\"\n",
        "\n",
        "# Text splitter\n",
        "chunk_size = 300\n",
        "chunk_overlap = 50\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Chunk the document\n",
        "chunks = text_splitter.create_documents(\n",
        "    texts=[document_content],\n",
        "    metadatas=[{\"source\": documents}]\n",
        ")\n",
        "\n",
        "# Display the first chunk\n",
        "print(chunks[0])\n",
        "print(\"=\" * 50)  # Separation line between documents\n",
        "\n",
        "# Calculate the number of chunks\n",
        "num_chunks = len(chunks)\n",
        "print(f\"Number of Chunks: {num_chunks}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAqgrgDa2k-v"
      },
      "source": [
        "##### **Embed the chunk data**\n",
        "Now that we've created small chunks from our sections, we need a way to identify the most relevant ones for a given query. A very effective and quick method is to embed our data using a pretrained model and use the same model to embed the query. We can then compute the distance between all of the chunk embeddings and our query embedding to determine the top-k chunks. There are many different pretrained models to choose from to embed our data but the most popular ones can be discovered through HuggingFace's Massive Text Embedding Benchmark (MTEB) leaderboard.\n",
        "\n",
        "#### **Loading OpenAI Embeddings Model**\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's text-embedding-ada-002 for this task! (soon we'll be able to leverage OpenAI's newest embedding model which is waiting on an approved PR to be merged as we speak!)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8J3pv3KUGGCI"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbuhz_p5VyXp"
      },
      "source": [
        "##### **Creating a FAISS VectorStore**\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings.\n",
        "\n",
        "We'll be leveraging Meta's FAISS for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t2x430X2yj2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vector_store = FAISS.from_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mhdAuYbWy-h"
      },
      "source": [
        "#### **Creating a Retriever**\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "lp3wZ9VYWu5r"
      },
      "outputs": [],
      "source": [
        "# Define vectorstore as retriever to enable semantic search\n",
        "\n",
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etU0D-1YXBcv"
      },
      "source": [
        "#### **Testing our Retriever**\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2D-BI-GWu9-"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"Can the Agreement or any of its obligations be assigned??\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLV04RZ-Wu_1",
        "outputId": "7d54959c-472f-4289-fd9d-ac27be890bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='The Company may assign the Agreement to a successor of all or substantially all of its assets or business, provided the assignee has assumed the Company’s obligations under this Agreement.' metadata={'source': 'Combined_Contract_Advisory.docx'}\n",
            "page_content='may assign this Agreement and any or all of its rights and interest hereunder to any purchaser of all or substantially all its assets or designate such purchaser to perform its obligations hereunder.  Except as expressly provided herein, this Agreement is for the sole benefit of the parties hereto' metadata={'source': 'Combined_Contract_Advisory.docx'}\n",
            "page_content='Succession and Assignment; No Third-Party Beneficiaries.  Subject to the immediately following sentence, this Agreement will be binding upon and inure to the benefit of the parties hereto and their respective successors and permitted assigns, each of which such successors and permitted assigns will' metadata={'source': 'Combined_Contract_Advisory.docx'}\n",
            "page_content='between the parties, either oral or written. This Agreement may be modified only by a written amendment executed by both parties. This Agreement may not be assigned, sold, delegated or transferred in any manner by Advisor for any reason whatsoever. The Company may assign the Agreement to a' metadata={'source': 'Combined_Contract_Advisory.docx'}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZzaxNhLZ3r9"
      },
      "source": [
        "### **Creating a RAG Chain**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbRzt1v_aQkC"
      },
      "source": [
        "##### **Creating a Prompt Template**\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pZwQ9rIWvFI"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt_kJeXOaVDR",
        "outputId": "fb9bfcec-4f7b-4b2d-f9ae-21c0265e1b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acS_GY5TaoGc"
      },
      "source": [
        "As you can see - the prompt template is simple - but we'll create our own to be\n",
        "\n",
        "---\n",
        "\n",
        "a bit more specific!\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "mAMrk_R8aVTk"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"Answer the question based only on the following context. If you cannot answer the question with the context, please respond with 'I don't know':\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWKII6HNa8oF"
      },
      "source": [
        "#### **Setting Up our Basic QA Chain**\n",
        "Now we can instantiate our basic RAG chain!\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "x4nHI9AO698g"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOpOaqHlaV25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm4hBsY-ArxJ"
      },
      "source": [
        "#### **Let's test it out!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who owns the IP?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBrK-3RMyq8K",
        "outputId": "1fe33661-7833-4a5d-89bd-89181b01ef77"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Company owns the IP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**But the correct answer is**: Any Work Product, upon creation, shall be fully and exclusively owned by the Company. in some extent is good answer"
      ],
      "metadata": {
        "id": "DoP2RZ03zcfx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "rbjIXUhFaWCb"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\n",
        "The Advisory Services Agreement is a legal document between Cloud Investments Ltd. and Mr. Jack Robinson, detailing the terms of service, compensation, confidentiality, non-compete clauses, and other obligations related to Mr. Robinson providing advisory services to the company.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"Who are the parties to the Agreement and what are their defined names??\",\n",
        "    \"How well does the RAG system capture the termination notice period as specified in the agreement?\",\n",
        "    \"Can the RAG system accurately detail the compensation structure, including hourly fees, workspace expense, and other expenses?\",\n",
        "    \"Does the RAG system correctly identify and interpret the clauses related to assignment and non-compete obligations?\",\n",
        "    \"Can the RAG system accurately determine the ownership of IP resulting from the services provided?\",\n",
        "    \"How effectively does the RAG system identify and summarize the non-compete clause's duration and scope?\",\n",
        "    \"Can the RAG system accurately interpret the definition of a Billable Hour, excluding meals and travel time?\",\n",
        "    \"Does the RAG system correctly assess the Advisor's entitlement to social benefits?\",\n",
        "    \"How well does the RAG system handle the scenario where the Advisor claims compensation based on an employment relationship with the Company?\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for question in questions:\n",
        "    # Assuming retrieval_augmented_qa_chain is a function that takes a dictionary with the question and context\n",
        "    result = retrieval_augmented_qa_chain.invoke({\"context\": context, \"question\": question})\n",
        "    print(f\"Question: {question}\\nResponse: {result['response'].content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtV9j3UqwU8u",
        "outputId": "9f7bbcd5-ee08-458e-fa0b-dcb4b330bc4f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who are the parties to the Agreement and what are their defined names??\n",
            "Response: I don't know.\n",
            "\n",
            "Question: How well does the RAG system capture the termination notice period as specified in the agreement?\n",
            "Response: The RAG system does not capture the termination notice period as specified in the agreement.\n",
            "\n",
            "Question: Can the RAG system accurately detail the compensation structure, including hourly fees, workspace expense, and other expenses?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: Does the RAG system correctly identify and interpret the clauses related to assignment and non-compete obligations?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: Can the RAG system accurately determine the ownership of IP resulting from the services provided?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: How effectively does the RAG system identify and summarize the non-compete clause's duration and scope?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: Can the RAG system accurately interpret the definition of a Billable Hour, excluding meals and travel time?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: Does the RAG system correctly assess the Advisor's entitlement to social benefits?\n",
            "Response: I don't know.\n",
            "\n",
            "Question: How well does the RAG system handle the scenario where the Advisor claims compensation based on an employment relationship with the Company?\n",
            "Response: The RAG system does not handle the scenario where the Advisor claims compensation based on an employment relationship with the Company.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ_0aVDKxxDN"
      },
      "source": [
        "#### **Ragas Evaluation**\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evluating on every core metric today, but in order to do that - we'll need to creat a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLOeuO2GyAPZ"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "**NOTE**: This process will use `gpt-3.5-turbo-16k` as the base generator and `gpt-4` as the critic - if you're attempting to create a lot of samples please be aware of cost, as well as rate limits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N077kK5eyUyV"
      },
      "source": [
        "Let's create a new set of documents to ensure we're not accidentally creating a sample test set that favours our base model too much!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Note**:\n",
        "First I will evaluate on human annotated ground truth values then will learn how to RAGAs can help us generate test data."
      ],
      "metadata": {
        "id": "PSgWjtdDWLUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Test Data Set\n",
        "questions = [\n",
        "    \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\",\n",
        "    \"Would the Sellers be responsible if after the closing it is determined that there were inaccuracies in the representation provided by them where such inaccuracies are the result of the Sellers’ gross negligence?\",\n",
        "    \"How much is the escrow amount?\",\n",
        "    \"Is the escrow amount greater than the Retention Amount?\",\n",
        "    \"What is the purpose of the escrow?\",\n",
        "    \"May the Escrow Amount serve as a recourse for the Buyer in case of a breach of representations by the Company?\",\n",
        "    \"Are there any conditions to the closing?\",\n",
        "    \"Are Change of Control Payments considered a Seller Transaction Expense?\",\n",
        "    \"Would the aggregate amount payable by the Buyer to the Sellers be affected if it is determined that the actual Closing Debt Amount is greater than the estimated Closing Debt Amount?\",\n",
        "    \"Does the Buyer need to pay the Employees Closing Bonus Amount directly to the Company’s employees?\",\n",
        "    \"Does any of the Sellers provide a representation with respect to any Tax matters related to the Company?\",\n",
        "    \"Is any of the Sellers bound by a non-competition covenant after the Closing?\",\n",
        "    \"Whose consent is required for the assignment of the Agreement by the Buyer?\",\n",
        "    \"Does the Buyer need the Sellers’ consent in the event of an assignment of the Agreement to a third party who is not a Buyer’s Affiliate?\"\n",
        "]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ogkDK8SAHg5D"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "In real estate transactions, the escrow process ensures that both buyers and sellers fulfill their legal obligations through a neutral third party, the escrow agent. The escrow agent's responsibilities include:\n",
        "- Executing escrow instructions with reasonable skill and diligence.\n",
        "- Adhering strictly to the depositor's written instructions.\n",
        "- Communicating significant information to the principal parties, especially if it affects the transaction.\n",
        "The buyer will not lose their funds in case the seller fails to fulfill their obligations, safeguarding the buyer's interests and preventing any potential issues that may arise from faulty or fraudulent documentation.\n",
        "The escrow agent is not liable for losses due to negligence. However, the escrow holder is not liable for losses incurred by following instructions. The escrow agent delivers documents to the intended recipient once contract conditions are met, and the depositor has no control over the escrowed instrument. The beneficiary is entitled to the escrowed property upon fulfilling the contract's conditions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GMeTsww3luCx"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_answers = [\n",
        "    \"Except in the case of fraud, the Sellers have no liability for a breach of representations and warranties (See section  10.01)\",\n",
        "    \"Yes\",\n",
        "    \"$1,000,000\",\n",
        "    \"No\",\n",
        "    \"To serve as a recourse of the Buyer in case of post-closing adjustments of the purchase price. (See section  2.07(e))\",\n",
        "    \"No\",\n",
        "    \"No, as the signing and closing are simultaneous.\",\n",
        "    \"Yes. (See defining Sellers Transaction Expenses).\",\n",
        "    \"Yes (See Section  2.07)\",\n",
        "    \"No. (See Section  2.10)\",\n",
        "    \"No. Only the Company provides such a representation.\",\n",
        "    \"No.\",\n",
        "    \"If the assignment is to an Affiliate or purchaser of all of the Buyer’s assets, no consent is required. Otherwise, the consent of the Company and the Seller Representative is required.\",\n",
        "    \"No. If the assignment is not part of a sale of all or substantially all of the Buyer’s assets, the assignment requires the consent of the Company and the Seller’s Representative.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "3PgW4hs1luSS"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the questions, context, and ground truth into a single document\n",
        "combined_document = \"\\n\".join(questions + [context] + ground_truth_answers)\n",
        "documents = combined_document\n",
        "\n"
      ],
      "metadata": {
        "id": "XbUqwX5PAKOt"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Let's create a new set of documents to ensure we're not accidentally creating a\n",
        "\n",
        "sample test set that favours our base model too much!"
      ],
      "metadata": {
        "id": "bp9M_btqIQ1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Assuming you have loaded the document content as a string\n",
        "document_content = \"Your document content here...\"\n",
        "\n",
        "# Text splitter\n",
        "chunk_size = 300\n",
        "chunk_overlap = 50\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Chunk the document\n",
        "chunks = text_splitter.create_documents(\n",
        "    texts=[document_content],\n",
        "    metadatas=[{\"source\": \"your_document_source\"}]\n",
        ")\n",
        "\n",
        "# Display the first chunk\n",
        "print(chunks[0])\n",
        "print(\"=\" * 50)  # Separation line between documents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axiniFDkIy5M",
        "outputId": "55832750-8578-4154-fb0b-e1afbe569a8c"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Your document content here...' metadata={'source': 'your_document_source'}\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Assuming you have a list of documents\n",
        "documents = [\"Document 1 content...\", \"Document 2 content...\", \"Document 3 content...\"]\n",
        "\n",
        "# Text splitter\n",
        "chunk_size = 300\n",
        "chunk_overlap = 50\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        ")\n",
        "\n",
        "# Calculate the number of documents\n",
        "num_documents = len(documents)\n",
        "\n",
        "# Calculate the number of chunks for each document\n",
        "num_chunks_per_document = []\n",
        "for document_content in documents:\n",
        "    chunks = text_splitter.create_documents(\n",
        "        texts=[document_content],\n",
        "        metadatas=[{\"source\": \"your_document_source\"}]\n",
        "    )\n",
        "    num_chunks_per_document.append(len(chunks))\n",
        "\n",
        "# Calculate the total number of chunks\n",
        "total_chunks = sum(num_chunks_per_document)\n",
        "\n",
        "print(f\"Number of documents: {num_documents}\")\n",
        "print(f\"Number of chunks per document: {num_chunks_per_document}\")\n",
        "print(f\"Total number of chunks: {total_chunks}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tWn8KZsJzgc",
        "outputId": "7e0342f1-db99-42b4-f178-f31dbf8c0e8e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 3\n",
            "Number of chunks per document: [1, 1, 1]\n",
            "Total number of chunks: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "5MvjVq9-aWHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2b3bf5-125e-4534-d097-a7a42b0b56cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "question_schema = ResponseSchema(\n",
        "    name=\"question\",\n",
        "    description=\"a question about the context.\"\n",
        ")\n",
        "\n",
        "question_response_schemas = [\n",
        "    question_schema,\n",
        "]"
      ],
      "metadata": {
        "id": "wIz855gKKTLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
        "format_instructions = question_output_parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "yki0kK6AePZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_generation_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "bare_prompt_template = \"{content}\"\n",
        "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)"
      ],
      "metadata": {
        "id": "BLwjsfKuiCA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCfdJauMiCRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pynCXgHQiCTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIIekxXCiCY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ok0E6K50iCb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSHX5tALiCgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Waz7Wn0kiCiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UzR33KNmV7_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGr-xiNQmV9k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGwGLsjCmV_H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z6Z2UkFmWAk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LZWHwOzmWCC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6gbx3XqmWDW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOwTozgIaWJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}